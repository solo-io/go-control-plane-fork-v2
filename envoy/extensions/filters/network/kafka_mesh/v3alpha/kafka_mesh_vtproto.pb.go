// Code generated by protoc-gen-go-vtproto. DO NOT EDIT.
// source: contrib/envoy/extensions/filters/network/kafka_mesh/v3alpha/kafka_mesh.proto

package v3alpha

import (
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	bits "math/bits"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

func (m *KafkaMesh) MarshalVTStrict() (dAtA []byte, err error) {
	if m == nil {
		return nil, nil
	}
	size := m.SizeVT()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBufferVTStrict(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *KafkaMesh) MarshalToVTStrict(dAtA []byte) (int, error) {
	size := m.SizeVT()
	return m.MarshalToSizedBufferVTStrict(dAtA[:size])
}

func (m *KafkaMesh) MarshalToSizedBufferVTStrict(dAtA []byte) (int, error) {
	if m == nil {
		return 0, nil
	}
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.unknownFields != nil {
		i -= len(m.unknownFields)
		copy(dAtA[i:], m.unknownFields)
	}
	if m.ConsumerProxyMode != 0 {
		i = encodeVarint(dAtA, i, uint64(m.ConsumerProxyMode))
		i--
		dAtA[i] = 0x28
	}
	if len(m.ForwardingRules) > 0 {
		for iNdEx := len(m.ForwardingRules) - 1; iNdEx >= 0; iNdEx-- {
			size, err := m.ForwardingRules[iNdEx].MarshalToSizedBufferVTStrict(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarint(dAtA, i, uint64(size))
			i--
			dAtA[i] = 0x22
		}
	}
	if len(m.UpstreamClusters) > 0 {
		for iNdEx := len(m.UpstreamClusters) - 1; iNdEx >= 0; iNdEx-- {
			size, err := m.UpstreamClusters[iNdEx].MarshalToSizedBufferVTStrict(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarint(dAtA, i, uint64(size))
			i--
			dAtA[i] = 0x1a
		}
	}
	if m.AdvertisedPort != 0 {
		i = encodeVarint(dAtA, i, uint64(m.AdvertisedPort))
		i--
		dAtA[i] = 0x10
	}
	if len(m.AdvertisedHost) > 0 {
		i -= len(m.AdvertisedHost)
		copy(dAtA[i:], m.AdvertisedHost)
		i = encodeVarint(dAtA, i, uint64(len(m.AdvertisedHost)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *KafkaClusterDefinition) MarshalVTStrict() (dAtA []byte, err error) {
	if m == nil {
		return nil, nil
	}
	size := m.SizeVT()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBufferVTStrict(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *KafkaClusterDefinition) MarshalToVTStrict(dAtA []byte) (int, error) {
	size := m.SizeVT()
	return m.MarshalToSizedBufferVTStrict(dAtA[:size])
}

func (m *KafkaClusterDefinition) MarshalToSizedBufferVTStrict(dAtA []byte) (int, error) {
	if m == nil {
		return 0, nil
	}
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.unknownFields != nil {
		i -= len(m.unknownFields)
		copy(dAtA[i:], m.unknownFields)
	}
	if len(m.ConsumerConfig) > 0 {
		for k := range m.ConsumerConfig {
			v := m.ConsumerConfig[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarint(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarint(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarint(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x2a
		}
	}
	if len(m.ProducerConfig) > 0 {
		for k := range m.ProducerConfig {
			v := m.ProducerConfig[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarint(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarint(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarint(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if m.PartitionCount != 0 {
		i = encodeVarint(dAtA, i, uint64(m.PartitionCount))
		i--
		dAtA[i] = 0x18
	}
	if len(m.BootstrapServers) > 0 {
		i -= len(m.BootstrapServers)
		copy(dAtA[i:], m.BootstrapServers)
		i = encodeVarint(dAtA, i, uint64(len(m.BootstrapServers)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.ClusterName) > 0 {
		i -= len(m.ClusterName)
		copy(dAtA[i:], m.ClusterName)
		i = encodeVarint(dAtA, i, uint64(len(m.ClusterName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ForwardingRule) MarshalVTStrict() (dAtA []byte, err error) {
	if m == nil {
		return nil, nil
	}
	size := m.SizeVT()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBufferVTStrict(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ForwardingRule) MarshalToVTStrict(dAtA []byte) (int, error) {
	size := m.SizeVT()
	return m.MarshalToSizedBufferVTStrict(dAtA[:size])
}

func (m *ForwardingRule) MarshalToSizedBufferVTStrict(dAtA []byte) (int, error) {
	if m == nil {
		return 0, nil
	}
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.unknownFields != nil {
		i -= len(m.unknownFields)
		copy(dAtA[i:], m.unknownFields)
	}
	if msg, ok := m.Trigger.(*ForwardingRule_TopicPrefix); ok {
		size, err := msg.MarshalToSizedBufferVTStrict(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
	}
	if len(m.TargetCluster) > 0 {
		i -= len(m.TargetCluster)
		copy(dAtA[i:], m.TargetCluster)
		i = encodeVarint(dAtA, i, uint64(len(m.TargetCluster)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ForwardingRule_TopicPrefix) MarshalToVTStrict(dAtA []byte) (int, error) {
	size := m.SizeVT()
	return m.MarshalToSizedBufferVTStrict(dAtA[:size])
}

func (m *ForwardingRule_TopicPrefix) MarshalToSizedBufferVTStrict(dAtA []byte) (int, error) {
	i := len(dAtA)
	i -= len(m.TopicPrefix)
	copy(dAtA[i:], m.TopicPrefix)
	i = encodeVarint(dAtA, i, uint64(len(m.TopicPrefix)))
	i--
	dAtA[i] = 0x12
	return len(dAtA) - i, nil
}
func encodeVarint(dAtA []byte, offset int, v uint64) int {
	offset -= sov(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *KafkaMesh) SizeVT() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.AdvertisedHost)
	if l > 0 {
		n += 1 + l + sov(uint64(l))
	}
	if m.AdvertisedPort != 0 {
		n += 1 + sov(uint64(m.AdvertisedPort))
	}
	if len(m.UpstreamClusters) > 0 {
		for _, e := range m.UpstreamClusters {
			l = e.SizeVT()
			n += 1 + l + sov(uint64(l))
		}
	}
	if len(m.ForwardingRules) > 0 {
		for _, e := range m.ForwardingRules {
			l = e.SizeVT()
			n += 1 + l + sov(uint64(l))
		}
	}
	if m.ConsumerProxyMode != 0 {
		n += 1 + sov(uint64(m.ConsumerProxyMode))
	}
	n += len(m.unknownFields)
	return n
}

func (m *KafkaClusterDefinition) SizeVT() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.ClusterName)
	if l > 0 {
		n += 1 + l + sov(uint64(l))
	}
	l = len(m.BootstrapServers)
	if l > 0 {
		n += 1 + l + sov(uint64(l))
	}
	if m.PartitionCount != 0 {
		n += 1 + sov(uint64(m.PartitionCount))
	}
	if len(m.ProducerConfig) > 0 {
		for k, v := range m.ProducerConfig {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sov(uint64(len(k))) + 1 + len(v) + sov(uint64(len(v)))
			n += mapEntrySize + 1 + sov(uint64(mapEntrySize))
		}
	}
	if len(m.ConsumerConfig) > 0 {
		for k, v := range m.ConsumerConfig {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sov(uint64(len(k))) + 1 + len(v) + sov(uint64(len(v)))
			n += mapEntrySize + 1 + sov(uint64(mapEntrySize))
		}
	}
	n += len(m.unknownFields)
	return n
}

func (m *ForwardingRule) SizeVT() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.TargetCluster)
	if l > 0 {
		n += 1 + l + sov(uint64(l))
	}
	if vtmsg, ok := m.Trigger.(interface{ SizeVT() int }); ok {
		n += vtmsg.SizeVT()
	}
	n += len(m.unknownFields)
	return n
}

func (m *ForwardingRule_TopicPrefix) SizeVT() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.TopicPrefix)
	n += 1 + l + sov(uint64(l))
	return n
}

func sov(x uint64) (n int) {
	return (bits.Len64(x|1) + 6) / 7
}
func soz(x uint64) (n int) {
	return sov(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
